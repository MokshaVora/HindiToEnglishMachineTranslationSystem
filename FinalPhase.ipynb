{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalPhase.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsVshh_KogLT"
      },
      "source": [
        "import re\n",
        "import csv\n",
        "import torch\n",
        "import random\n",
        "import collections\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.utils import data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4WgUKtL68nE"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSh9j4AxzPi5"
      },
      "source": [
        "#**Required Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVbugVEgZypi"
      },
      "source": [
        "def train_test_split(lang1, lang2, ratio=0.8):\n",
        "    '''split data into train and test sets with the given ratio'''\n",
        "    if ratio == 1:\n",
        "        train_hin, train_eng, val_hin, val_eng = lang1[:], lang2[:], [], []\n",
        "    else:\n",
        "        instances = len(lang1)\n",
        "        train_size = int(instances * ratio)\n",
        "        train_hin, train_eng, val_hin, val_eng = [], [], [], []\n",
        "\n",
        "        #randomly sample indices \n",
        "        indices = random.sample(range(instances), train_size)\n",
        "        for index in range(instances):\n",
        "            if index in indices:\n",
        "                train_hin.append(lang1[index])\n",
        "                train_eng.append(lang2[index])\n",
        "            else:\n",
        "                val_hin.append(lang1[index])\n",
        "                val_eng.append(lang2[index])\n",
        "    return train_hin, train_eng, val_hin, val_eng"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k67ODL1_osAd"
      },
      "source": [
        "def tokenize(s, lang):\n",
        "    '''tokenize the string'''\n",
        "    if lang == 'hin':\n",
        "        #replace everything except hindi alphabets and space\n",
        "        s = re.sub(r'[^\\s\\u0900-\\u0963\\u0970-\\u097f]+', ' ', s)\n",
        "        s = re.sub(r' +', ' ', s)\n",
        "\n",
        "    elif lang == 'eng':\n",
        "        #replace everything except english alphabets and space\n",
        "        s = re.sub(r'[^\\s\\u0041-\\u005a\\u0061-\\u007a]+', ' ', s)\n",
        "        s = re.sub(r' +', ' ', s)\n",
        "        #convert to lowercase\n",
        "        s = s.lower()\n",
        "\n",
        "    #tokenize by spliting at space\n",
        "    tokens = s.split(' ')\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnFyrHk_BrzR"
      },
      "source": [
        "**Reference:** https://d2l.ai/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx1zZmKqwGAB"
      },
      "source": [
        "class Vocab:\n",
        "    '''Create vocabulary'''\n",
        "\n",
        "    def __init__(self, tokens, min_freq, reserved_tokens):\n",
        "        #count the frequency of tokens\n",
        "        counter = count_corpus(tokens)\n",
        "\n",
        "        self.token_freqs = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
        "        self.unk, uniq_tokens = 0, ['<unk>'] + reserved_tokens\n",
        "\n",
        "        #make a list of tokens with frequency > min_freq\n",
        "        uniq_tokens += [\n",
        "            token for token, freq in self.token_freqs\n",
        "            if freq >= min_freq and token not in uniq_tokens]\n",
        "\n",
        "        #generate dict to create token_id\n",
        "        self.idx_to_token, self.token_to_idx = [], dict()\n",
        "        for token in uniq_tokens:\n",
        "            self.idx_to_token.append(token)\n",
        "            self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx_to_token)\n",
        "\n",
        "    def __getitem__(self, tokens):\n",
        "        '''convert token to id'''\n",
        "        if not isinstance(tokens, (list, tuple)):\n",
        "            return self.token_to_idx.get(tokens, self.unk)\n",
        "        return [self.__getitem__(token) for token in tokens]\n",
        "\n",
        "    def to_tokens(self, indices):\n",
        "        '''convert id to token'''\n",
        "        if not isinstance(indices, (list, tuple)):\n",
        "            return self.idx_to_token[indices]\n",
        "        return [self.idx_to_token[index] for index in indices]\n",
        "\n",
        "def count_corpus(tokens):  \n",
        "    '''count the frequency of tokens'''\n",
        "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
        "        tokens = [token for line in tokens for token in line]\n",
        "    return collections.Counter(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kes1qOyNaPHm"
      },
      "source": [
        "def truncate_pad(line, num_steps, padding_token):\n",
        "    '''make string length = num_steps by truncating or padding'''\n",
        "    if len(line) > num_steps:\n",
        "        return line[:num_steps]  \n",
        "    return line + [padding_token] * (num_steps - len(line)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xz5BIPRC-8D"
      },
      "source": [
        "def build_array(lines, vocab, num_steps):\n",
        "    '''add <eos> to the string and convert it into tensor'''\n",
        "    lines = [vocab[l] for l in lines]\n",
        "    lines = [l + [vocab['<eos>']] for l in lines]\n",
        "    array = torch.tensor([\n",
        "        truncate_pad(l, num_steps, vocab['<pad>']) for l in lines])\n",
        "    valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n",
        "    return array, valid_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdsSuDbMaHf2"
      },
      "source": [
        "def load_array(data_arrays, batch_size, is_train=True):\n",
        "    '''returns the data iterator'''\n",
        "    dataset = data.TensorDataset(*data_arrays)\n",
        "    return data.DataLoader(dataset, batch_size, shuffle=is_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_nnT7q3PgRo"
      },
      "source": [
        "class EpochLoss:\n",
        "    '''sum the epoch loss and no. of tokens'''\n",
        "    def __init__(self, n):\n",
        "        self.data = [0.0] * n\n",
        "    def add(self, *args):\n",
        "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwo8aiFjdSkD"
      },
      "source": [
        "def sequence_mask(X, valid_len, value=0):\n",
        "    '''mask padding added to the string'''\n",
        "    maxlen = X.size(1)\n",
        "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
        "                        device=X.device)[None, :] < valid_len[:, None]\n",
        "    X[~mask] = value\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdzskQ3fcyoG"
      },
      "source": [
        "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
        "    '''softmax cross-entropy loss with mask'''\n",
        "    #'pred': ('batch_size', 'num_steps', 'vocab_size')\n",
        "    #'label': ('batch_size', 'num_steps')\n",
        "    #'valid_len': ('batch_size', )\n",
        "    def forward(self, pred, label, valid_len):\n",
        "        weights = torch.ones_like(label)\n",
        "        weights = sequence_mask(weights, valid_len)\n",
        "        self.reduction = 'none'\n",
        "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(pred.permute(0, 2, 1), label)\n",
        "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
        "        return weighted_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtJEJ_023RfI"
      },
      "source": [
        "def masked_softmax(X, valid_len):\n",
        "    '''Perform softmax function after masking padding in the last axis'''\n",
        "    #'X': ('batch_size', 1, 'num_steps') \n",
        "    #'valid_len': ('batch_size', )\n",
        "    shape = X.shape\n",
        "    valid_len = torch.repeat_interleave(valid_len, shape[1])\n",
        "    X = sequence_mask(X.reshape(-1, shape[-1]), valid_len, value=-1e6)\n",
        "    return nn.functional.softmax(X.reshape(shape), dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "805ZYr7W1pze"
      },
      "source": [
        "###**Bidirectional GRU Encoder** \n",
        "##Check comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtTyxFNf44On"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    '''Bidirectional GRU encoder'''\n",
        "\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout, **kwargs):\n",
        "        super().__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        #embedding layer\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        #Bidirectional GRU \n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout = dropout, bidirectional=True)\n",
        "        self.fc = nn.Linear(hid_dim * 2, hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, *args):\n",
        "        #'input': ('batch_size', 'num_steps') \n",
        "        #'embedded': ('batch_size', 'num_steps', 'emb_dim') \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        #RNN accepts input with first dim as num_steps\n",
        "        embedded = embedded.permute(1, 0, 2)\n",
        "        output, hidden = self.rnn(embedded)   \n",
        "        #concate the hidden states of forward and backward GRU cells\n",
        "        concated = torch.cat((hidden[0:hidden.size(0):2], hidden[1:hidden.size(0):2]), dim=2)\n",
        "        hidden = torch.tanh(self.fc(concated)) \n",
        "        #'output': ('num_steps', 'batch_size', 2*'hid_dim') \n",
        "        #'hidden': ('n_layers', 'batch_size', 'hid_dim') \n",
        "        return output, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msZDJQfg1521"
      },
      "source": [
        "###**GRU Decoder with Bahdanau Attention**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG-zDMVnZyT6"
      },
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs):\n",
        "        super().__init__()\n",
        "        self.W_k = nn.Linear(2 * key_size, num_hiddens, bias=False)\n",
        "        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n",
        "        self.w_v = nn.Linear(num_hiddens, 1, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, queries, keys, values, valid_lens):\n",
        "        queries, keys = self.W_q(queries), self.W_k(keys)  \n",
        "        features = queries.unsqueeze(2) + keys.unsqueeze(1)\n",
        "        features = torch.tanh(features)\n",
        "        scores = self.w_v(features).squeeze(-1)\n",
        "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
        "        return torch.bmm(self.dropout(self.attention_weights), values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srd6WAWSHTyp"
      },
      "source": [
        "class AttentionDecoder(nn.Module):\n",
        "    '''GRU Decoder with Attention'''\n",
        "    \n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout=0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        #Bahdanau Attention\n",
        "        self.attention = BahdanauAttention(hid_dim, hid_dim, hid_dim, dropout)\n",
        "        #embedding layer\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        #GRU \n",
        "        self.rnn = nn.GRU(emb_dim + 2 * hid_dim, hid_dim, n_layers, dropout=dropout)\n",
        "        self.dense = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        " \n",
        "    def init_state(self, enc_output, enc_valid_len, *args):\n",
        "        #'outputs': ('num_steps', 'batch_size', 2*'hid_dim').\n",
        "        #'hidden': ('n_layers', 'batch_size', 'hid_dim')\n",
        "        output, hidden = enc_output\n",
        "        return [output.permute(1, 0, 2), hidden, enc_valid_len]\n",
        " \n",
        "    def forward(self, output, state):\n",
        "        #'enc_outputs': ('batch_size', 'num_steps', 2*'hid_dim')\n",
        "        #'hidden': ('n_layers', 'batch_size', 'hid_dim')\n",
        "        #'enc_valid_lens': ('batch_size', )\n",
        "        enc_outputs, hidden, enc_valid_lens = state\n",
        "        #'output': ('num_steps, 'batch_size', 'emb_dim') (After the following step)\n",
        "        output = self.dropout(self.embedding(output)).permute(1, 0, 2)\n",
        "        outputs = []\n",
        "        for x in output:\n",
        "            #'query': ('batch_size', 1, 'hid_dim')\n",
        "            query = torch.unsqueeze(hidden[-1], dim=1)\n",
        "            #'context': ('batch_size', 1, 2*'hid_dim')\n",
        "            context = self.attention(query, enc_outputs, enc_outputs, enc_valid_lens)\n",
        "            #Concatenate the context and x\n",
        "            x = torch.cat((context, torch.unsqueeze(x, dim=1)), dim=-1)\n",
        "            #Reshape 'x' as (1, 'batch_size', 'emb_dim' + 2*'hid_dim')\n",
        "            out, hidden = self.rnn(x.permute(1, 0, 2), hidden)\n",
        "            outputs.append(out)\n",
        "        outputs = self.dense(torch.cat(outputs, dim=0))\n",
        "        #'outputs': ('num_steps', 'batch_size', 'vocab_size')\n",
        "        return outputs.permute(1, 0, 2), [enc_outputs, hidden, enc_valid_lens]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZgsxft73TGN"
      },
      "source": [
        "###**Seq2Seq Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xboD6fN_9IdD"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "    def forward(self, src, trg, *args):\n",
        "        enc_outputs = self.encoder(src, *args)\n",
        "        state = self.decoder.init_state(enc_outputs, *args)\n",
        "        return self.decoder(trg, state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGECZVa73Z3m"
      },
      "source": [
        "###Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06tV_hKt-17q"
      },
      "source": [
        "def train(model, data_iter, lr, num_epochs, tgt_vocab, device):\n",
        "    '''train a seq2seq model'''\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        #sum the training loss\n",
        "        eloss = EpochLoss(2)\n",
        "        for batch in data_iter:\n",
        "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
        "\n",
        "            #add <sos> to the start of output string \n",
        "            sos = torch.tensor([tgt_vocab['<sos>']] * Y.shape[0],\n",
        "                                device=device).reshape(-1, 1)\n",
        "            #teacher forcing\n",
        "            dec_input = torch.cat([sos, Y[:, :-1]], 1)  \n",
        "            Y_hat, _ = model(X, dec_input, X_valid_len)\n",
        "            l = loss(Y_hat, Y, Y_valid_len)\n",
        "            #propogate loss backward\n",
        "            l.sum().backward() \n",
        "            #clip the gradient to avoid exploding gradients\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "            num_tokens = Y_valid_len.sum()\n",
        "            optimizer.step()\n",
        "            with torch.no_grad():\n",
        "                eloss.add(l.sum(), num_tokens)\n",
        "        print(epoch + 1,' Loss: ', eloss[0] / eloss[1])\n",
        "    print(f'Final Loss: {eloss[0] / eloss[1]:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws8wZ-MY3fbj"
      },
      "source": [
        "###Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KArLAmJ9423C"
      },
      "source": [
        "def predict_seq2seq(model, input, hin_vocab, eng_vocab, num_steps, device):\n",
        "    '''prediction for seq2seq model'''\n",
        "    model.eval()\n",
        "\n",
        "    str_h = tokenize(input, 'hin')\n",
        "    str_h = list(filter(('').__ne__, str_h))\n",
        "    hin_tokens = hin_vocab[str_h] + [hin_vocab['<eos>']] \n",
        "    enc_valid_len = torch.tensor([len(hin_tokens)], device=device)\n",
        "    hin_tokens = truncate_pad(hin_tokens, num_steps, hin_vocab['<pad>'])\n",
        "    \n",
        "    #add the batch axis\n",
        "    enc_X = torch.unsqueeze(torch.tensor(hin_tokens, dtype=torch.long, device=device), dim=0)\n",
        "    enc_outputs = model.encoder(enc_X, enc_valid_len)\n",
        "    state = model.decoder.init_state(enc_outputs, enc_valid_len)\n",
        "    \n",
        "    #add the batch axis\n",
        "    dec_X = torch.unsqueeze(torch.tensor([eng_vocab['<sos>']], dtype=torch.long, device=device), dim=0)\n",
        "    \n",
        "    output_seq = []\n",
        "    for _ in range(num_steps):\n",
        "        Y, state = model.decoder(dec_X, state)\n",
        "        #greedy decoding (use the token with the highest prediction likelihood as the input of decoder at next time step)\n",
        "        dec_X = Y.argmax(dim=2)\n",
        "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
        "        #break when the <eos> token is predicted\n",
        "        if pred == eng_vocab['<eos>']:\n",
        "            break\n",
        "        output_seq.append(pred)\n",
        "    return ' '.join(eng_vocab.to_tokens(output_seq))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYouGUJXzE-m"
      },
      "source": [
        "#**Main** **Code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PNxlnwnzxjo"
      },
      "source": [
        "Read train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_-kIKPby_AB"
      },
      "source": [
        "hindi, english = [], []\n",
        "#read train dataset\n",
        "with open('/content/drive/MyDrive/AssignmentNLP/train/train.csv', 'r') as file:\n",
        "    lines = csv.reader(file)\n",
        "    for line in lines:\n",
        "        hindi.append(line[1])\n",
        "        english.append(line[2])\n",
        "hindi = hindi[1:]\n",
        "english = english[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPc0udT9z10M"
      },
      "source": [
        "Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPpotE7bzA0x"
      },
      "source": [
        "train_hin, train_eng, val_hin, val_eng = train_test_split(hindi, english, ratio=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y_4Gc3wz5ns"
      },
      "source": [
        "Tokenize dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM_Bx6CSsJHJ"
      },
      "source": [
        "hin_tokens = []\n",
        "eng_tokens = []\n",
        "for h, e in zip(train_hin, train_eng):\n",
        "    str_h = tokenize(h, 'hin')\n",
        "    str_h = list(filter(('').__ne__, str_h))\n",
        "    if len(str_h) != 0:\n",
        "        str_e = tokenize(e, 'eng')\n",
        "        str_e = list(filter(('').__ne__, str_e))\n",
        "        hin_tokens.append(str_h)\n",
        "        eng_tokens.append(str_e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AedOr49vz9kL"
      },
      "source": [
        "Create Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahqGb0S_z0D1"
      },
      "source": [
        "hin_vocab = Vocab(hin_tokens, min_freq=2, reserved_tokens=['<pad>', '<sos>', '<eos>'])\n",
        "eng_vocab = Vocab(eng_tokens, min_freq=2, reserved_tokens=['<pad>', '<sos>', '<eos>'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkX2YNxF0A8b"
      },
      "source": [
        "Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BobLm81690nH"
      },
      "source": [
        "INPUT_DIM = len(hin_vocab)\n",
        "OUTPUT_DIM = len(eng_vocab)\n",
        "ENC_EMB_DIM = 64\n",
        "DEC_EMB_DIM = 64 \n",
        "HID_DIM = 128\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.25\n",
        "DEC_DROPOUT = 0.25\n",
        "LR = 0.001\n",
        "NUM_EPOCHS = 10\n",
        "num_steps = 20 \n",
        "batch_size = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQW8lm0R0MIz"
      },
      "source": [
        "Create Tensors and Data iterators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyNdLihY3aPP"
      },
      "source": [
        "hin_array, hin_valid_len = build_array(hin_tokens, hin_vocab, num_steps)\n",
        "eng_array, eng_valid_len = build_array(eng_tokens, eng_vocab, num_steps)\n",
        "data_arrays = (hin_array, hin_valid_len, eng_array, eng_valid_len)\n",
        "data_iter = load_array(data_arrays, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZSlrrma0SHm"
      },
      "source": [
        "Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myyAXhPeNKCr"
      },
      "source": [
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = AttentionDecoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnP5byX50U7L"
      },
      "source": [
        "Initialize weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YyCewqc-BEu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84865f8c-3ba9-41df-b772-898c9a9c562b"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "model.apply(init_weights).to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(20453, 64)\n",
              "    (rnn): GRU(64, 128, num_layers=2, dropout=0.25, bidirectional=True)\n",
              "    (fc): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (dropout): Dropout(p=0.25, inplace=False)\n",
              "  )\n",
              "  (decoder): AttentionDecoder(\n",
              "    (attention): BahdanauAttention(\n",
              "      (W_k): Linear(in_features=256, out_features=128, bias=False)\n",
              "      (W_q): Linear(in_features=128, out_features=128, bias=False)\n",
              "      (w_v): Linear(in_features=128, out_features=1, bias=False)\n",
              "      (dropout): Dropout(p=0.25, inplace=False)\n",
              "    )\n",
              "    (embedding): Embedding(18317, 64)\n",
              "    (rnn): GRU(320, 128, num_layers=2, dropout=0.25)\n",
              "    (dense): Linear(in_features=128, out_features=18317, bias=True)\n",
              "    (dropout): Dropout(p=0.25, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD9nQcXC0Ye_"
      },
      "source": [
        "Define optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDJeBoJN-pR0"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=LR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbEGINLv0cRk"
      },
      "source": [
        "Define loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd3rZ-PQc4c4"
      },
      "source": [
        "loss = MaskedSoftmaxCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o05qYsmn0flp"
      },
      "source": [
        "Training phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gr7Caq3pjfG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "dd4de633-8af5-490f-9b2f-ddcc66ba6e6a"
      },
      "source": [
        "train(model, data_iter, LR, NUM_EPOCHS, eng_vocab, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1  Loss:  0.2801650961754046\n",
            "2  Loss:  0.24657784568008312\n",
            "3  Loss:  0.23073072298620254\n",
            "4  Loss:  0.21871594098685376\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-f0e79de42b0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-8a8e5fbfb844>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_iter, lr, num_epochs, tgt_vocab, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m#propogate loss backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0;31m#clip the gradient to avoid exploding gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72bbxp5T0iKE"
      },
      "source": [
        "Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7SQ6BGwDZ5G"
      },
      "source": [
        "#torch.save(model.state_dict(), '/content/drive/MyDrive/AssignmentNLP/TrialFinal/train_model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAkDAFFl0kJ_"
      },
      "source": [
        "Predict validation set answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0oGRSN3PLtA"
      },
      "source": [
        "'''answers = []\n",
        "for l in val_hin:\n",
        "    answers.append(predict_seq2seq(model, l, hin_vocab, eng_vocab, num_steps, device, True)[0])'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCOx58j3HS9a"
      },
      "source": [
        "'''with open('/content/drive/MyDrive/AssignmentNLP/TrialFinal/val_ans.txt', 'w') as f:\n",
        "    for l in answers[:-1]:\n",
        "        f.write(l +'\\n')\n",
        "    f.write(answers[-1])'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCrVN4880zCo"
      },
      "source": [
        "Load testset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTp9uDk4Y7Fm"
      },
      "source": [
        "hindi_st = []\n",
        "with open('/content/drive/MyDrive/AssignmentNLP/Testset/testhindistatements.csv', 'r') as file:\n",
        "    lines = csv.reader(file)\n",
        "    for line in lines:\n",
        "        hindi_st.append(line[2])\n",
        "hindi_st = hindi_st[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmeJUs-J04bY"
      },
      "source": [
        "Predict testset answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJZ01H6VgTo5"
      },
      "source": [
        "hind = 'आप का शुक्रिया'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cUuTAZssgDsI",
        "outputId": "551fe644-9681-4bc0-9635-3ec39fbf1a58"
      },
      "source": [
        "predict_seq2seq(model, hind, hin_vocab, eng_vocab, num_steps, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'thank you for you'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS7scnY_2cHV"
      },
      "source": [
        "ans = []\n",
        "for l in hindi_st:\n",
        "    ans.append(predict_seq2seq(model, l, hin_vocab, eng_vocab, num_steps, device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACoemxe85N4H"
      },
      "source": [
        "with open('/content/drive/MyDrive/AssignmentNLP/TrialFinal/answer.txt', 'w') as f:\n",
        "    for l in ans[:-1]:\n",
        "        f.write(l +'\\n')\n",
        "    f.write(ans[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBzz75A4cXhK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d6dae14-e0ee-487f-c3d5-114682d565d4"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/AssignmentNLP/TrialFinal/train_model.pt'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D_lnBq9f8I3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}