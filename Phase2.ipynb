{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Phase2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsVshh_KogLT"
      },
      "source": [
        "import unicodedata as ucd\n",
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "import collections\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.utils import data"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GHNWFLxU2hb"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVbugVEgZypi"
      },
      "source": [
        "def train_test_split(lang1, lang2, ratio=0.8):\n",
        "    instances = lang1.shape[0]\n",
        "    train_size = int(instances * ratio)\n",
        "    train_hin = []\n",
        "    train_eng = []\n",
        "    val_hin = []\n",
        "    val_eng = []\n",
        "    indices = random.sample(range(instances), train_size)\n",
        "    for index in range(instances):\n",
        "        if index in indices:\n",
        "            train_hin.append(lang1[index])\n",
        "            train_eng.append(lang2[index])\n",
        "        else:\n",
        "            val_hin.append(lang1[index])\n",
        "            val_eng.append(lang2[index])\n",
        "    return train_hin, train_eng, val_hin, val_eng"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k67ODL1_osAd"
      },
      "source": [
        "def tokenize(s, lang):\n",
        "    if lang == 'hin':\n",
        "        s = re.sub(r'[^\\s\\u0900-\\u0963\\u0970-\\u097f]+', ' ', s)\n",
        "        s = re.sub(r' +', ' ', s)\n",
        "    elif lang == 'eng':\n",
        "        s = re.sub(r'[^\\s\\u0041-\\u005a\\u0061-\\u007a]+', ' ', s)\n",
        "        s = re.sub(r' +', ' ', s)\n",
        "        s = s.lower()\n",
        "    tokens = s.split(' ')\n",
        "    return tokens"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dXKpNSMpesL"
      },
      "source": [
        "**Reference:** https://d2l.ai/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoFX2mkAsIyV"
      },
      "source": [
        "class Vocab:\n",
        "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
        "        if tokens is None:\n",
        "            tokens = []\n",
        "        if reserved_tokens is None:\n",
        "            reserved_tokens = []\n",
        "        counter = count_corpus(tokens)\n",
        "        self.token_freqs = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
        "        self.unk, uniq_tokens = 0, ['<unk>'] + reserved_tokens\n",
        "        uniq_tokens += [\n",
        "            token for token, freq in self.token_freqs\n",
        "            if freq >= min_freq and token not in uniq_tokens]\n",
        "        self.idx_to_token, self.token_to_idx = [], dict()\n",
        "        for token in uniq_tokens:\n",
        "            self.idx_to_token.append(token)\n",
        "            self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx_to_token)\n",
        "\n",
        "    def __getitem__(self, tokens):\n",
        "        if not isinstance(tokens, (list, tuple)):\n",
        "            return self.token_to_idx.get(tokens, self.unk)\n",
        "        return [self.__getitem__(token) for token in tokens]\n",
        "\n",
        "    def to_tokens(self, indices):\n",
        "        if not isinstance(indices, (list, tuple)):\n",
        "            return self.idx_to_token[indices]\n",
        "        return [self.idx_to_token[index] for index in indices]\n",
        "\n",
        "def count_corpus(tokens):  \n",
        "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
        "        tokens = [token for line in tokens for token in line]\n",
        "    return collections.Counter(tokens)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kes1qOyNaPHm"
      },
      "source": [
        "def truncate_pad(line, num_steps, padding_token):\n",
        "    if len(line) > num_steps:\n",
        "        return line[:num_steps]  \n",
        "    return line + [padding_token] * (num_steps - len(line)) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xz5BIPRC-8D"
      },
      "source": [
        "def build_array(lines, vocab, num_steps):\n",
        "    lines = [vocab[l] for l in lines]\n",
        "    lines = [l + [vocab['<eos>']] for l in lines]\n",
        "    array = torch.tensor([truncate_pad(l, num_steps, vocab['<pad>']) for l in lines])\n",
        "    valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n",
        "    return array, valid_len"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdsSuDbMaHf2"
      },
      "source": [
        "def load_array(data_arrays, batch_size, is_train=True):\n",
        "    dataset = data.TensorDataset(*data_arrays)\n",
        "    return data.DataLoader(dataset, batch_size, shuffle=is_train)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_nnT7q3PgRo"
      },
      "source": [
        "class EpochLoss:\n",
        "    def __init__(self, n):\n",
        "        self.data = [0.0] * n\n",
        "    def add(self, *args):\n",
        "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
        "    def reset(self):\n",
        "        self.data = [0.0] * len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtTyxFNf44On"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout, **kwargs):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, *args):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        embedded = embedded.permute(1, 0, 2)\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)        \n",
        "        return outputs, (hidden, cell)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueGD6n5onUCP"
      },
      "source": [
        "def masked_softmax(X, valid_lens):\n",
        "    if valid_lens is None:\n",
        "        return nn.functional.softmax(X, dim=-1)\n",
        "    else:\n",
        "        shape = X.shape\n",
        "        if valid_lens.dim() == 1:\n",
        "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
        "        else:\n",
        "            valid_lens = valid_lens.reshape(-1)\n",
        "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=-1e6)\n",
        "        return nn.functional.softmax(X.reshape(shape), dim=-1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG-zDMVnZyT6"
      },
      "source": [
        "class AdditiveAttention(nn.Module):\n",
        "    def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs):\n",
        "        super(AdditiveAttention, self).__init__(**kwargs)\n",
        "        self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n",
        "        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n",
        "        self.w_v = nn.Linear(num_hiddens, 1, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, queries, keys, values, valid_lens):\n",
        "        queries, keys = self.W_q(queries), self.W_k(keys)\n",
        "        features = queries.unsqueeze(2) + keys.unsqueeze(1)\n",
        "        features = torch.tanh(features)\n",
        "        scores = self.w_v(features).squeeze(-1)\n",
        "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
        "        return torch.bmm(self.dropout(self.attention_weights), values)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srd6WAWSHTyp"
      },
      "source": [
        "class AttentionDecoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout=0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.attention = AdditiveAttention(hid_dim, hid_dim, hid_dim, dropout)\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim + hid_dim, hid_dim, n_layers, dropout=dropout)\n",
        "        self.dense = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
        "        outputs, (hidden, cell) = enc_outputs\n",
        "        return [outputs.permute(1, 0, 2), (hidden, cell), enc_valid_lens]\n",
        "\n",
        "    def forward(self, X, state):\n",
        "        enc_outputs, (hidden, cell), enc_valid_lens = state\n",
        "        X = self.dropout(self.embedding(X)).permute(1, 0, 2)\n",
        "        outputs, self._attention_weights = [], []\n",
        "        for x in X:\n",
        "            query = torch.unsqueeze(hidden[-1], dim=1)\n",
        "            context = self.attention(query, enc_outputs, enc_outputs, enc_valid_lens)\n",
        "            x = torch.cat((context, torch.unsqueeze(x, dim=1)), dim=-1)\n",
        "            out, (hidden, cell) = self.rnn(x.permute(1, 0, 2), (hidden, cell))\n",
        "            outputs.append(out)\n",
        "            self._attention_weights.append(self.attention.attention_weights)\n",
        "        outputs = self.dense(torch.cat(outputs, dim=0))\n",
        "        return outputs.permute(1, 0, 2), [enc_outputs, (hidden, cell), enc_valid_lens]\n",
        "\n",
        "    @property\n",
        "    def attention_weights(self):\n",
        "        return self._attention_weights"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJshOKCZBcVS"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "    def forward(self, src, trg, *args):\n",
        "        enc_outputs = self.encoder(src, *args)\n",
        "        state = self.decoder.init_state(enc_outputs, *args)\n",
        "        return self.decoder(trg, state)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3ogXpnaBcVS"
      },
      "source": [
        "def train(model, data_iter, lr, num_epochs, eng_vocab, device):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        metric = EpochLoss(2)\n",
        "        for batch in data_iter:\n",
        "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
        "            sos = torch.tensor([eng_vocab['<sos>']] * Y.shape[0],\n",
        "                                device=device).reshape(-1, 1)\n",
        "            dec_input = torch.cat([sos, Y[:, :-1]], 1)  \n",
        "            Y_hat, _ = model(X, dec_input, X_valid_len)\n",
        "            l = criterion(Y_hat, Y, Y_valid_len)\n",
        "            l.sum().backward() \n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "            num_tokens = Y_valid_len.sum()\n",
        "            optimizer.step()\n",
        "            with torch.no_grad():\n",
        "                metric.add(l.sum(), num_tokens)\n",
        "        print(epoch + 1, ' Loss: ', metric[0] / metric[1])\n",
        "    print(f'Final Loss: {metric[0] / metric[1]:.4f}')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwo8aiFjdSkD"
      },
      "source": [
        "def sequence_mask(X, valid_len, value=0):\n",
        "    maxlen = X.size(1)\n",
        "    mask = torch.arange((maxlen), dtype=torch.float32, device=X.device)[None, :] < valid_len[:, None]\n",
        "    X[~mask] = value\n",
        "    return X"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdzskQ3fcyoG"
      },
      "source": [
        "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
        "    def forward(self, pred, label, valid_len):\n",
        "        weights = torch.ones_like(label)\n",
        "        weights = sequence_mask(weights, valid_len)\n",
        "        self.reduction = 'none'\n",
        "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(pred.permute(0, 2, 1), label)\n",
        "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
        "        return weighted_loss"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niqLwi7HsI-G"
      },
      "source": [
        "'''df = pd.read_csv('/content/drive/MyDrive/AssignmentNLP/train/train.csv')\n",
        "hindi = df.iloc[:, 1].values\n",
        "english = df.iloc[:, 2].values\n",
        "train_hin, train_eng, val_hin, val_eng = train_test_split(hindi, english)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_FYp5JkBlKZ"
      },
      "source": [
        "with open('/content/drive/MyDrive/AssignmentNLP/Trial1/train_hin.txt', 'r') as f:\n",
        "    train_hin = f.read().splitlines()\n",
        "\n",
        "with open('/content/drive/MyDrive/AssignmentNLP/Trial1/train_eng.txt', 'r') as f:\n",
        "    train_eng = f.read().splitlines()\n",
        "\n",
        "with open('/content/drive/MyDrive/AssignmentNLP/Trial1/val_hin.txt', 'r') as f:\n",
        "    val_hin = f.read().splitlines()\n",
        "\n",
        "with open('/content/drive/MyDrive/AssignmentNLP/Trial1/val_eng.txt', 'r') as f:\n",
        "    val_eng = f.read().splitlines()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM_Bx6CSsJHJ"
      },
      "source": [
        "hin = []\n",
        "eng = []\n",
        "for h, e in zip(train_hin, train_eng):\n",
        "    str_h = tokenize(h, 'hin')\n",
        "    str_h = list(filter(('').__ne__, str_h))\n",
        "    if len(str_h) != 0:\n",
        "        str_e = tokenize(e, 'eng')\n",
        "        str_e = list(filter(('').__ne__, str_e))\n",
        "        hin.append(str_h)\n",
        "        eng.append(str_e)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahqGb0S_z0D1"
      },
      "source": [
        "hin_vocab = Vocab(hin, min_freq=2, reserved_tokens=['<pad>', '<sos>', '<eos>'])\n",
        "eng_vocab = Vocab(eng, min_freq=2, reserved_tokens=['<pad>', '<sos>', '<eos>'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mfE_mLNBcVT"
      },
      "source": [
        "INPUT_DIM = len(hin_vocab)\n",
        "OUTPUT_DIM = len(eng_vocab)\n",
        "ENC_EMB_DIM = 50\n",
        "DEC_EMB_DIM = 50 \n",
        "HID_DIM = 128\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.25\n",
        "DEC_DROPOUT = 0.25\n",
        "LR = 0.001\n",
        "NUM_EPOCHS = 300\n",
        "NUM_STEPS = 15 \n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyNdLihY3aPP"
      },
      "source": [
        "hin_array, hin_valid_len = build_array(hin, hin_vocab, NUM_STEPS)\n",
        "eng_array, eng_valid_len = build_array(eng, eng_vocab, NUM_STEPS)\n",
        "data_arrays = (hin_array, hin_valid_len, eng_array, eng_valid_len)\n",
        "data_iter = load_array(data_arrays, BATCH_SIZE)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myyAXhPeNKCr"
      },
      "source": [
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = AttentionDecoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YyCewqc-BEu"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "model.apply(init_weights).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDJeBoJN-pR0"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=LR)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wVmTLu_-yaY"
      },
      "source": [
        "criterion = MaskedSoftmaxCELoss()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gr7Caq3pjfG"
      },
      "source": [
        "train(model, data_iter, LR, NUM_EPOCHS, eng_vocab, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7SQ6BGwDZ5G"
      },
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/AssignmentNLP/Trial12/train_model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnLn_DoHC_Ba"
      },
      "source": [
        "def predict_seq2seq(model, src_sentence, src_vocab, tgt_vocab, num_steps, device, save_attention_weights=False):\n",
        "    model.eval()\n",
        "    str_h = normalize(src_sentence, 'hin')\n",
        "    str_h = list(filter(('').__ne__, str_h))\n",
        "    src_tokens = src_vocab[str_h] + [src_vocab['<eos>']]\n",
        "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
        "    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
        "    enc_X = torch.unsqueeze(torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
        "    enc_outputs = model.encoder(enc_X, enc_valid_len)\n",
        "    state = model.decoder.init_state(enc_outputs, enc_valid_len)\n",
        "    dec_X = torch.unsqueeze(torch.tensor([tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
        "    output_seq, attention_weight_seq = [], []\n",
        "    for _ in range(num_steps):\n",
        "        Y, state = model.decoder(dec_X, state)\n",
        "        dec_X = Y.argmax(dim=2)\n",
        "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
        "        if save_attention_weights:\n",
        "            attention_weight_seq.append(model.decoder.attention_weights)\n",
        "        if pred == tgt_vocab['<eos>']:\n",
        "            break\n",
        "        output_seq.append(pred)\n",
        "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0oGRSN3PLtA"
      },
      "source": [
        "val_ans = []\n",
        "for l in val_hin:\n",
        "    val_ans.append(predict_seq2seq(model, l, hin_vocab, eng_vocab, NUM_STEPS, device)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCOx58j3HS9a"
      },
      "source": [
        "with open('/content/drive/MyDrive/AssignmentNLP/Trial12/val_ans.txt', 'w') as f:\n",
        "    for l in val_ans[:-1]:\n",
        "        f.write(l +'\\n')\n",
        "    f.write(val_ans[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w41CzIm4Xcie"
      },
      "source": [
        "!pip install -U nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBq2Jyfssdie"
      },
      "source": [
        "import nltk\n",
        "import sys\n",
        "nltk.download('wordnet')\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.meteor_score import single_meteor_score\n",
        "\n",
        "references = val_eng\n",
        "hypotheses = val_ans\n",
        "\n",
        "total_num = len(references)\n",
        "total_bleu_scores = 0\n",
        "total_meteor_scores = 0\n",
        "for i in range(total_num):\n",
        "  total_bleu_scores+=sentence_bleu([references[i].split(\" \")], hypotheses[i].split(\" \"))\n",
        "  total_meteor_scores+=single_meteor_score(references[i], hypotheses[i])\n",
        "\n",
        "bleu_result = total_bleu_scores/total_num\n",
        "meteor_result = total_meteor_scores/total_num\n",
        "\n",
        "print(\"bleu score: \",bleu_result)\n",
        "print(\"meteor score: \",meteor_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTp9uDk4Y7Fm"
      },
      "source": [
        "import pandas as pd\n",
        "data_frame = pd.read_csv('/content/drive/MyDrive/AssignmentNLP/Week2/hindistatements.csv')\n",
        "hindi_st = list(data_frame.iloc[:, 2].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS7scnY_2cHV"
      },
      "source": [
        "ans = []\n",
        "for l in hindi_st:\n",
        "    ans.append(predict_seq2seq(model, l, hin_vocab, eng_vocab, NUM_STEPS, device)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACoemxe85N4H"
      },
      "source": [
        "with open('/content/drive/MyDrive/AssignmentNLP/Trial12/answer.txt', 'w') as f:\n",
        "    for l in ans[:-1]:\n",
        "        f.write(l +'\\n')\n",
        "    f.write(ans[-1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}